#graph.py
#
# This file will be used to build graph for LangGraph studio
# There are some issues with the clera_main.py file that prevent it from being used in LangGraph studio
# So this file will be used to build the graph

#clera_main.py
# This is the main file for the Clera application.
# It is used to orchestrate the flow of the application.
# It takes in a Clera instance, a FinancialNewsAgent instance, and a PortfolioRebalanceAgent instance.
# It then builds the graph and executes it.

#!/usr/bin/env python3
import os
import sys
import json
import uuid
from datetime import datetime, timezone
from dotenv import load_dotenv
from typing import List, Optional, Any, Dict, Tuple, Union, Annotated
from typing_extensions import TypedDict

# ---------------------------
# Load environment variables FIRST before any agent imports
# ---------------------------
os.environ["TOKENIZERS_PARALLELISM"] = "false"
load_dotenv(override=True)

# ---------------------------
# Import LangChain / LangGraph components
# ---------------------------
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage, FunctionMessage
from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate
from langchain_core.tools import Tool, tool
from langchain.agents.format_scratchpad.log_to_messages import format_log_to_messages
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langgraph.store.memory import InMemoryStore
#from langmem import create_manage_memory_tool, create_search_memory_tool # deleted langmem for now
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph_supervisor import create_supervisor
from langgraph.prebuilt import create_react_agent
from langgraph.types import interrupt

# Import embeddings function from openAI
#from ...

# ---------------------------
# Import LLM clients (GroqCloud, Anthropic, OpenAI & Perplexity)
# ---------------------------
from langchain_groq import ChatGroq
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain_perplexity import ChatPerplexity
# instead of using langchain_community.chat_models.ChatPerplexity


# ---------------------------
# Import tools for agents to use (AFTER environment variables are loaded)
# ---------------------------
from clera_agents import financial_analyst_agent as fa_module
from clera_agents import portfolio_management_agent as pm_module
from clera_agents import trade_execution_agent as te_module

# Import personalization service and supervisor prompt
from utils.personalization_service import create_personalized_supervisor_prompt
from utils.prompts.supervisor_prompt import get_supervisor_clera_system_prompt


###############################################################################
# Define the conversation state type
###############################################################################
class State(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    # Removed fields previously used for manual context passing if not needed by graph logic itself
    # next_step: str
    # current_agent: str
    # agent_scratchpad: List[BaseMessage]
    # retrieved_context: List[str]
    # last_user_input: str
    # answered_user: bool
    account_id: Optional[str] # Context now passed via config/state
    user_id: Optional[str]   # Context now passed via config/state

    # Keep supervisor state fields
    is_last_step: bool
    remaining_steps: int

###############################################################################
# Set up storage and checkpointer
###############################################################################
#store = InMemoryStore(
#    index={
#        "dims": 1536,
#        "embed": get_embeddings,
#    }
#) 

checkpointer = MemorySaver()

###############################################################################
# Define Tools for Specialized Agents to Use
###############################################################################

chat_perplexity = ChatPerplexity(
    temperature=0.4,
    model="sonar"
) 

# Define tools for each agent upfront
financial_analyst_tools = [
    fa_module.web_search,
    fa_module.get_stock_price,
    fa_module.calculate_investment_performance
]

portfolio_management_tools = [
    pm_module.get_portfolio_summary,
    pm_module.rebalance_instructions,
    pm_module.get_account_activities_tool
]

trade_execution_tools = [
    te_module.execute_buy_market_order,
    te_module.execute_sell_market_order
]

###############################################################################
# Build the Graph
###############################################################################



# other llms: llama-3.1-8b-instant, llama-3.3-70b-versatile (using ChatGroq)
main_llm = ChatAnthropic(
    anthropic_api_key=os.environ.get("ANTHROPIC_API_KEY"),
    model="claude-sonnet-4-20250514",
    temperature=0.1,  # Research shows lower temp prevents function calling errors
    max_retries=3,
    timeout=120,  # Anthropic uses 'timeout' not 'request_timeout'
    streaming=True,  # CRITICAL: Enable streaming for token-by-token output
    stream_usage=True  # Also include usage metadata in streaming
)
    

financial_analyst_llm = ChatAnthropic(
    anthropic_api_key=os.environ.get("ANTHROPIC_API_KEY"),
    model="claude-3-5-haiku-20241022",  
    temperature=0.1,  # Lower temp for reliable function calling
    max_retries=3,
    timeout=120,  # Anthropic uses 'timeout' not 'request_timeout'
    streaming=True,  # CRITICAL: Enable streaming for token-by-token output
    stream_usage=True  # Also include usage metadata in streaming
)

# Use the more reliable llama-3.3-70b-versatile model for function calling
rebalance_llm = ChatAnthropic(
    anthropic_api_key=os.environ.get("ANTHROPIC_API_KEY"),
    model="claude-3-5-haiku-20241022",
    temperature=0.2,
    max_retries=3,
    timeout=120,
    streaming=True,  # CRITICAL: Enable streaming for token-by-token output
    stream_usage=True  # Also include usage metadata in streaming
)



#trade_llm = ChatGroq(
#    groq_api_key=os.environ.get("GROQ_API_KEY"),
#    model_name="llama-3.3-70b-versatile",
#    temperature=0.2,
#    max_retries=3,
#    request_timeout=60
#)

trade_llm = ChatAnthropic(
    anthropic_api_key=os.environ.get("ANTHROPIC_API_KEY"),
    model="claude-3-5-haiku-20241022",
    temperature=0.2,
    max_retries=3,
    timeout=60,
    streaming=True,  # CRITICAL: Enable streaming for token-by-token output
    stream_usage=True  # Also include usage metadata in streaming
)

current_datetime = datetime.now(timezone.utc).strftime('%A, %B %d, %Y at %I:%M %p UTC')

financial_analyst_agent = create_react_agent(
    model=financial_analyst_llm,
    tools=financial_analyst_tools,
    prompt=f"""You are an expert financial analyst specializing in equity research and market analysis. Today is {current_datetime}.

## YOUR ROLE
Provide institutional-quality research and analysis on securities, markets, and investment opportunities. Focus on objective, data-driven insights that inform investment decisions.

## TOOL USAGE STRATEGY

### **web_search** - Market Research & Analysis
**Primary Use**: Investment recommendations, analyst opinions, company fundamentals
**Search Patterns**:
- "[TICKER] analyst price target buy rating Wall Street research 2025"
- "[TICKER] earnings revenue guidance analyst estimates latest"  
- "[TICKER] valuation P/E ratio compared peers sector analysis"
- "[TICKER] recent news catalysts developments Q4 2024"

### **get_stock_price** - Current Market Data
**Use for**: Current price, daily performance, market context
**Always include**: Price level, daily change, 52-week context when available

### **calculate_investment_performance** - Historical Analysis  
**Use for**: Performance comparison, volatility analysis, benchmark comparison
**Default to S&P 500 comparison**: Include relative performance vs market

## INVESTMENT RECOMMENDATION FRAMEWORK

When analyzing securities for investment potential:

1. **CURRENT VALUATION**
   - Get current price using get_stock_price
   - Research analyst price targets and ratings
   - Compare valuation metrics to peers/sector

2. **FUNDAMENTAL ANALYSIS**  
   - Search recent earnings, revenue trends, guidance
   - Identify key business drivers and catalysts
   - Assess competitive position and market dynamics

3. **TECHNICAL & SENTIMENT ANALYSIS**
   - Recent price performance vs benchmarks
   - Analyst sentiment and rating changes
   - Institutional investor activity if available

## CRITICAL EXECUTION RULES
- **ALWAYS call tools when requested** - never just provide cached knowledge
- **Use current date context** - today is {current_datetime}
- **Focus on recent data** - prioritize latest earnings, recent analyst reports
- **Combine multiple tools** - use 2-3 tools per analysis for comprehensive view

4. **RISK ASSESSMENT**
   - Company-specific risks (regulatory, competitive, execution)
   - Sector/market risks affecting the stock
   - Valuation risk (overvalued vs undervalued analysis)

## OUTPUT REQUIREMENTS

**Investment Analysis Structure**:
- **Current Status**: Price, analyst consensus, recent performance
- **Investment Thesis**: Key reasons to buy/sell/hold with supporting data
- **Valuation Assessment**: Fair value estimate vs current price
- **Key Risks**: Primary downside risks to consider
- **Catalyst Timeline**: Upcoming events that could drive performance

**Quality Standards**:
- Lead with specific data points (prices, ratios, percentages)
- Reference credible sources (analyst reports, company filings)
- Provide balanced view (bull case AND bear case)
- Include actionable insights for investment decisions

## EXAMPLE WORKFLOWS

**Query**: "Is Palantir a good buy right now?"
**Approach**:
1. web_search("PLTR analyst price target buy rating Wall Street research 2025")
2. get_stock_price("PLTR") 
3. calculate_investment_performance("PLTR", start_date="2024-01-01", end_date="2025-01-17")
4. Synthesize: Current valuation, analyst views, performance context, investment recommendation

**Query**: "How is Apple performing lately?"  
**Approach**:
1. get_stock_price("AAPL")
2. calculate_investment_performance("AAPL", start_date="2024-10-01", end_date="2025-01-17")
3. web_search("AAPL recent earnings performance news Q4 2024")

Focus on delivering professional-grade analysis that institutional investors would expect.""",
    name="financial_analyst_agent",
    state_schema=State
)

portfolio_management_agent = create_react_agent(
    model=rebalance_llm,
    tools=portfolio_management_tools,
    prompt=f"""You are a portfolio management specialist focusing on the user's specific investment account. Today is {current_datetime}.

## YOUR EXPERTISE
Analyze the user's actual portfolio holdings, performance, and provide personalized investment guidance based on their current positions and financial situation.

## AVAILABLE TOOLS - USER'S PORTFOLIO ONLY

=== 1. get_portfolio_summary() ===
Purpose: Shows the user's actual portfolio holdings, positions, performance, and live account value
When to use: ANY question about their current portfolio state, holdings, positions, allocation, balance, value, performance

Example queries that ALL use get_portfolio_summary():
- "Show my portfolio"
- "What do I own?"
- "What are my holdings?"
- "What's my portfolio worth?"
- "How is my portfolio performing?"
- "What's my current allocation?"
- "Show me my positions"
- "What's my account balance?"
- "How much cash do I have?"
- "What stocks do I own?"
- "What ETFs are in my portfolio?"
- "What's my portfolio value?"
- "How much money do I have invested?"
- "What's my asset allocation?"
- "Show me my investment breakdown"

EXACT function call:
get_portfolio_summary()

=== 2. rebalance_instructions() ===
Purpose: Provides specific rebalancing advice for the user's current portfolio holdings
When to use: ANY question about rebalancing, adjusting allocation, portfolio optimization

Example queries that ALL use rebalance_instructions():
- "How should I rebalance my portfolio?"
- "Should I rebalance?"
- "How can I optimize my allocation?"
- "What adjustments should I make?"
- "How do I improve my portfolio balance?"
- "Should I change my allocation?"
- "How can I better diversify?"
- "What rebalancing do you recommend?"
- "How should I adjust my holdings?"
- "Is my portfolio properly balanced?"

EXACT function call:
rebalance_instructions()

=== 3. get_account_activities() ===
PURPOSE: Comprehensive trading history and account activities report
SCOPE: LAST 60 DAYS ONLY (current date minus 60 days maximum)
INCLUDES:
• Complete trading history (all buy and sell transactions)
• Trading statistics (buy/sell counts, total volume, unique symbols)
• Account activities (dividends, fees, transfers, etc.)
• First purchase dates for stocks (when available)
• Detailed transaction information with dates, times, quantities, prices

WHEN TO USE: ANY question about trading history, transactions, or account activities
Example queries that ALL use get_account_activities():
- "What have I bought recently?"
- "Show me my trading history"
- "What transactions have I made?"
- "Show me my purchase history"
- "What stocks have I traded?"
- "When did I first buy [stock]?"
- "What have I sold?"
- "Show me my account activities"
- "What's my trading activity?"
- "How many trades have I made?"
- "What have I purchased?"

CRITICAL LIMITATIONS:
• ONLY shows last 60 days of data
• Cannot retrieve data older than 60 days
• If user asks for data beyond 60 days (e.g., "last year", "6 months ago"), the tool will still only return 60 days

HOW TO HANDLE REQUESTS BEYOND 60 DAYS:
When user asks for trading history beyond 60 days, call the tool anyway (it's the best we have), 
then explain in your response that the data is limited to the last 60 days.

Example: User asks "Show me all my trades from last year"
→ Call get_account_activities()
→ Tool returns 60-day data
→ Include a note like: "Here's your trading history from the last 60 days (this is the maximum data available):"

EXACT function call:
get_account_activities()

TOOL SELECTION LOGIC:
- Current portfolio state/holdings/value → get_portfolio_summary()
- Changing/adjusting/rebalancing portfolio → rebalance_instructions()
- Trading history/transactions/account activities → get_account_activities()

EXAMPLES:

Human: "What do I currently own?"
→ get_portfolio_summary()

Human: "How much is my portfolio worth?"
→ get_portfolio_summary()

Human: "Should I rebalance?"
→ rebalance_instructions()

Human: "What's my allocation between stocks and bonds?"
→ get_portfolio_summary()

Human: "How can I improve my diversification?"
→ rebalance_instructions()

H: "What have I bought recently?"
→ get_account_activities()

H: "Show me my trading history"
→ get_account_activities()

H: "When did I first buy Apple?"
→ get_account_activities()

H: "What transactions have I made this year?"
→ get_account_activities() (will show last 60 days, mention limitation)

## PORTFOLIO CONTEXT ANALYSIS - CRITICAL FOR INVESTMENT QUESTIONS

When analyzing investment opportunities in context of user's portfolio:

### **Current Position Assessment**
- Check if user already owns the security (get_portfolio_summary)
- Analyze current allocation and concentration risk
- Determine portfolio fit and diversification impact

### **Strategic Recommendations**
- Consider user's existing risk profile and allocation
- Assess whether addition fits investment strategy
- Recommend position sizing based on portfolio value
- Identify potential rebalancing needs

### **Investment Context Questions**
When user asks about specific securities (e.g., "Is PLTR a good investment?"):
1. **ALWAYS check current holdings first** - "Let me look at your current portfolio to see if you already own PLTR and how it would fit your allocation"
2. **Analyze portfolio context**: Position sizing, diversification impact, risk considerations
3. **Provide personalized guidance**: Based on their specific situation, not generic advice

**Example**: "Is Palantir a good buy?" → get_portfolio_summary() first to check current PLTR position and portfolio context

Focus on personalized portfolio management that considers their unique financial situation.""",
    name="portfolio_management_agent",
    state_schema=State
)

trade_execution_agent = create_react_agent(
    model=trade_llm,
    tools=trade_execution_tools,
    prompt='''You are a trade execution assistant. Today's date and time is {}. 

Your role is to execute buy and sell orders for users using your available tools.

YOUR AVAILABLE TOOLS:

=== 1. execute_buy_market_order(ticker: str, notional_amount: float) ===
Purpose: Buy stocks/ETFs using a dollar amount (market order)
When to use: ANY buy request with ticker and dollar amount

EXACT function call format:
execute_buy_market_order(ticker="AAPL", notional_amount=500.0)
execute_buy_market_order(ticker="VTI", notional_amount=1000.0)
execute_buy_market_order(ticker="MSFT", notional_amount=250.0)

=== 2. execute_sell_market_order(ticker: str, notional_amount: float) ===
Purpose: Sell stocks/ETFs using a dollar amount (market order)
When to use: ANY sell request with ticker and dollar amount

EXACT function call format:
execute_sell_market_order(ticker="AAPL", notional_amount=500.0)
execute_sell_market_order(ticker="VTI", notional_amount=1000.0)
execute_sell_market_order(ticker="TSLA", notional_amount=750.0)

VALID REQUEST FORMATS YOU MUST HANDLE:
- "Buy $500 of AAPL"
- "Buy $1000 worth of Apple"
- "Purchase $250 of VTI"
- "Sell $500 of Tesla"
- "Sell $1000 of AAPL"
- "Buy 500 dollars of Microsoft"
- "Sell $750 worth of SPY"
- "Invest $500 in Apple"
- "Put $1000 into TSLA"
- "Buy five hundred dollars of Amazon"
- "Sell 250 dollars worth of NVDA"

INVALID REQUESTS (explain why without calling tool):
- "Buy AAPL" (missing amount)
- "Buy some Apple" (missing amount)
- "Sell all my AAPL" (need specific dollar amount)
- "Buy 10 shares of AAPL" (we use dollar amounts, not shares)
- "Buy $0.50 of AAPL" (below $1.00 minimum)

CRITICAL RULES:
* Process ONLY ONE trade per invocation
* NEVER fabricate success messages - MUST call a tool first for valid requests
* Always extract ticker symbol in uppercase format
* Always extract dollar amount as a float
* Minimum trade amount is $1.00
* If multiple trades requested, process ONLY the first one
* Return EXACTLY the raw tool output as final answer

EXAMPLES:

Input: "Buy $500 of AAPL"
→ execute_buy_market_order(ticker="AAPL", notional_amount=500.0)
Final Answer: [Exact tool response]

Input: "Sell $1000 of Tesla"
→ execute_sell_market_order(ticker="TSLA", notional_amount=1000.0)
Final Answer: [Exact tool response]

Input: "Buy $250 worth of VTI"
→ execute_buy_market_order(ticker="VTI", notional_amount=250.0)
Final Answer: [Exact tool response]

Input: "Buy $500 of SPY and sell $500 of AAPL" (multiple trades)
→ execute_buy_market_order(ticker="SPY", notional_amount=500.0)
Final Answer: [Exact tool response]

Input: "Buy some Apple stock"
Final Answer: Cannot execute trade - missing dollar amount. Please specify how much you want to invest (e.g., "Buy $500 of AAPL").

Input: "Sell all my AAPL"
Response: Cannot execute trade - need specific dollar amount. Please specify how much to sell (e.g., "Sell $1000 of AAPL").

Always validate requests have both ticker and dollar amount before executing trades. Use the appropriate tool for valid requests.'''.format(current_datetime),
    name="trade_execution_agent",
    state_schema=State
)


# Create supervisor workflow with personalized system prompt
workflow = create_supervisor(
    [financial_analyst_agent, portfolio_management_agent, trade_execution_agent],
    model=main_llm,
    prompt=create_personalized_supervisor_prompt,  # Function instead of static string
    output_mode="full_history", 
    supervisor_name="Clera", 
    state_schema=State
) # tools=[fa_module.web_search]  # we can add tools if you want

# Compile with memory components
graph = workflow.compile()
# No need for checkpointer or memory store because we're using LangGraph deployment
# checkpointer=checkpointer, store=store # is what it would typically look like

graph.name = "CleraAgents" # This defines a custom name in LangSmith + LangGraph Studio

__all__ = ["graph"] # This allows the graph to be imported from the file
